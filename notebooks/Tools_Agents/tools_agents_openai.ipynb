{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550331c8",
   "metadata": {},
   "source": [
    "# Buliding Agent with Tools Wikipedia, Arxiv, and RAG (OpenAI Embeddings) using LangChain and GROQ LLM\n",
    "\n",
    "In this notebook, we build a powerful multi-tool AI agent using LangChain and GROQ's fast and efficient LLaMA3 model. The agent can answer complex questions by combining reasoning with external knowledge sources and custom document retrieval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a35df",
   "metadata": {},
   "source": [
    "### Create Tools "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc2f55",
   "metadata": {},
   "source": [
    "#### Tool for Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56794211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Create wrapper for Wikipedia API\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(\n",
    "    top_k_results=1,\n",
    "    doc_content_chars_max=250\n",
    ")\n",
    "# Create function to query Wikipedia\n",
    "wiki_func = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "wiki_func.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8101e97",
   "metadata": {},
   "source": [
    "#### Tool for Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c11b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "# Create wrapper for Arxiv API\n",
    "arxiv_api_wrapper = ArxivAPIWrapper(\n",
    "    top_k_results=1,\n",
    "    doc_content_chars_max=250\n",
    ")\n",
    "# Create function to query Arxiv\n",
    "arxiv_func = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)\n",
    "print(arxiv_func.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b54c5e",
   "metadata": {},
   "source": [
    "#### Custom Tool (RAG Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247b6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "{'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "# Create a web loader for a specific URL\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=\"https://docs.smith.langchain.com/\"\n",
    ")\n",
    "docs = web_loader.load()\n",
    "# Print the loaded documents\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50])  # Print the first 100 characters of each document\n",
    "    print(doc.metadata)  # Print metadata of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d95976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter to split documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "# Split the loaded documents into smaller chunks\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# Print the first chunk of the first document\n",
    "print(split_docs[0].page_content[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b14b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a vector store using FAISS with the embeddings model\n",
    "vector_store = FAISS.from_documents(\n",
    "    split_docs,\n",
    "    OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# Print the number of documents in the vector store\n",
    "print(len(vector_store.index_to_docstore_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10d7e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025DBAD17580>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "# print the retriever's search type and number of results to return\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e807887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='LangSmithSearch', description='A tool to retrieve from the LangSmith knowledge base.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000025DC7B82710>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025DBAD17580>, search_kwargs={'k': 2}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000025DC7E339A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025DBAD17580>, search_kwargs={'k': 2}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retriever tool using the retriever\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# Create a retriever tool using the retriever\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"LangSmithSearch\",\n",
    "    description=\"A tool to retrieve from the LangSmith knowledge base.\"\n",
    ")\n",
    "\n",
    "# Print the retriever tool's name and description\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4b5ea",
   "metadata": {},
   "source": [
    "#### Create Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66eb0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "<class 'langchain_community.tools.wikipedia.tool.WikipediaQueryInput'>\n",
      "\n",
      "arxiv\n",
      "A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n",
      "<class 'langchain_community.tools.arxiv.tool.ArxivInput'>\n",
      "\n",
      "LangSmithSearch\n",
      "A tool to retrieve from the LangSmith knowledge base.\n",
      "<class 'langchain_core.tools.retriever.RetrieverInput'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tools = [wiki_func, arxiv_func, retriever_tool]\n",
    "# Print the names of the tools\n",
    "for tool in tools:\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(tool.args_schema)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d1b39",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b923ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000025DBB298430>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000025DBB29A380>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Groq model using the Groq API\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import openai\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"Llama3-8b-8192\",\n",
    "    api_key=groq_api_key\n",
    ")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f5a08",
   "metadata": {},
   "source": [
    "#### Pull structed prompt from LangChain Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a10ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232412c0",
   "metadata": {},
   "source": [
    "#### Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b294070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025DC7897400>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025DC7897400>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000025DBB298430>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000025DBB29A380>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'LangSmithSearch', 'description': 'A tool to retrieve from the LangSmith knowledge base.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "\n",
    "# Create an agent that uses the tools and the prompt\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be82e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025DC7897400>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025DC7897400>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000025DBB298430>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000025DBB29A380>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'LangSmithSearch', 'description': 'A tool to retrieve from the LangSmith knowledge base.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\SATISH-KUMAR\\\\GitRepos\\\\LangChain\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='LangSmithSearch', description='A tool to retrieve from the LangSmith knowledge base.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000025DC7B82710>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025DBAD17580>, search_kwargs={'k': 2}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000025DC7E339A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025DBAD17580>, search_kwargs={'k': 2}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Create an agent executor to run the agent with the tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f73d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Will Smith\n",
      "Summary: Willard Carroll  Smith II (born September 25, 1968) is an American actor, rapper, and film producer. He has received multiple accolades, including an Academy Award, a Golden Globe Award, a BAFTA Award, and four Grammy Awards\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that the tool call for \"call_0c7g\" yielded some information about Will Smith. However, I couldn't find any information about a knowledge base or database called \"LangSmith\". It's possible that it's a lesser-known or niche database.\n",
      "\n",
      "Since we didn't get any relevant information about \"LangSmith\", I'll respond directly to your question: I couldn't find any information about LangSmith, but I did find information about Will Smith, an American actor, rapper, and film producer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is LangSmith?',\n",
       " 'output': 'It seems that the tool call for \"call_0c7g\" yielded some information about Will Smith. However, I couldn\\'t find any information about a knowledge base or database called \"LangSmith\". It\\'s possible that it\\'s a lesser-known or niche database.\\n\\nSince we didn\\'t get any relevant information about \"LangSmith\", I\\'ll respond directly to your question: I couldn\\'t find any information about LangSmith, but I did find information about Will Smith, an American actor, rapper, and film producer.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is LangSmith?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b70344ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Alan Turing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Alan Turing\n",
      "Summary: Alan Mathison Turing (; 23 June 1912 ‚Äì 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretica\u001b[0m\u001b[32;1m\u001b[1;3mBased on the result, here is the response:\n",
      "\n",
      "Alan Turing was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. He was highly influential in the development of theoretical computer science, artificial intelligence, and the concept of the universal Turing machine. Turing is widely considered to be the father of computer science and artificial intelligence, and his work laid the foundation for a wide range of modern computer and information technologies.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is Alan Turing?',\n",
       " 'output': 'Based on the result, here is the response:\\n\\nAlan Turing was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. He was highly influential in the development of theoretical computer science, artificial intelligence, and the concept of the universal Turing machine. Turing is widely considered to be the father of computer science and artificial intelligence, and his work laid the foundation for a wide range of modern computer and information technologies.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Who is Alan Turing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20cb0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Recent papers on AI and Finance'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-06-05\n",
      "Title: Explaining AI in Finance: Past, Present, Prospects\n",
      "Authors: Barry Quinn\n",
      "Summary: This paper explores the journey of AI in finance, with a particular focus on\n",
      "the crucial role and potential of Explainable AI (XAI). We trac\u001b[0m\u001b[32;1m\u001b[1;3mHere's a brief summary:\n",
      "\n",
      "The paper \"Explaining AI in Finance: Past, Present, Prospects\" by Barry Quinn explores the journey of AI in finance, with a focus on the role and potential of Explainable AI (XAI). The paper tracks the evolution of AI applications in finance, from early attempts to the current state of the field, and discusses the challenges and opportunities of using XAI in finance.\n",
      "\n",
      "Would you like me to call another tool or provide more information on this paper?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Any recent papers on AI and Finance?',\n",
       " 'output': 'Here\\'s a brief summary:\\n\\nThe paper \"Explaining AI in Finance: Past, Present, Prospects\" by Barry Quinn explores the journey of AI in finance, with a focus on the role and potential of Explainable AI (XAI). The paper tracks the evolution of AI applications in finance, from early attempts to the current state of the field, and discusses the challenges and opportunities of using XAI in finance.\\n\\nWould you like me to call another tool or provide more information on this paper?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Any recent papers on AI and Finance?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b366315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LangSmithSearch` with `{'query': 'logging-traces'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî¬†it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability‚Äã\n",
      "\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability‚Äã\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\u001b[0m\u001b[32;1m\u001b[1;3mI've got the information you need. LangSmith is a platform for building production-grade LLM applications, and it allows you to closely monitor and evaluate your application. You can analyze traces in LangSmith, configure metrics, dashboards, and alerts, and also evaluate your application over production traffic.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How do I log traces in LangSmith?',\n",
       " 'output': \"I've got the information you need. LangSmith is a platform for building production-grade LLM applications, and it allows you to closely monitor and evaluate your application. You can analyze traces in LangSmith, configure metrics, dashboards, and alerts, and also evaluate your application over production traffic.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"How do I log traces in LangSmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf5d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
